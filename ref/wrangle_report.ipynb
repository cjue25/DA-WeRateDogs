{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangle_Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Four datasets: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Three input:\n",
    "\n",
    "- `twitter-archive-enhanced.csv`: the basic information of each tweet post. \n",
    "       \n",
    ">**Columns:**'tweet_id', 'in_reply_to_status_id', 'in_reply_to_user_id', 'timestamp',\n",
    ">'source', 'text', 'retweeted_status_id', 'retweeted_status_user_id',\n",
    ">'retweeted_status_timestamp', 'expanded_urls', 'rating_numerator',\n",
    ">'rating_denominator', 'name', 'doggo', 'floofer', 'pupper', 'puppo' \n",
    "    \n",
    "    \n",
    "- `image-predictions.tsv` : dog image for each tweet, including the predition of the breeds of the dog.\n",
    "    \n",
    ">**Columns:**\n",
    ">'tweet_id', 'jpg_url', 'img_num', 'p1', 'p1_conf', 'p1_dog', 'p2',\n",
    ">'p2_conf', 'p2_dog', 'p3', 'p3_conf', 'p3_dog'\n",
    "\n",
    "- `tweet_json.txt` : the retweet and favorite of each tweet.\n",
    "\n",
    ">**Columns:**\n",
    ">'tweet_id', 'retweet', 'favorite'\n",
    "\n",
    "### One ouput:\n",
    "\n",
    "- `twitter_archive_master.csv`: merge all the three input datasets.\n",
    "\n",
    ">**Columns:**\n",
    ">tweet_id', 'rating_denominator', 'rating_numerator', 'retweet',\n",
    ">      'favorite', 'name', 'breed', 'stage', 'text', 'confidence', 'timestamp',\n",
    ">       'expanded_urls', 'source', 'jpg_url'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Wrangle summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### **twitter-archive-enhanced.csv**\n",
    "1. Remove 78 non-null `in_reply` related columns\n",
    "2. Remove 181 non-null `retweet` related columns\n",
    "3. Change `timestamp` type to datetime\n",
    "4. Remove all the missing values in `expanded urls`\n",
    "5. Correct `name` by visual browsing of the text, still remain the \"None\" and \"unspecified\" records.\n",
    "6. Correct the value `rating_denominator` > 10\n",
    "7. Correct the extreme high value of `rating_numerator`\n",
    "8. Change `tweet_id ` type to object\n",
    "9. Check the stage `['doggo', 'floofer', 'pupper', 'puppo']`. Check the more than 1 stage and reduce it to the main stage by browsing the text and photo, then combine them into one column called \"stage\"\n",
    "10. Remove the unneccessary words such as \"</a>\" in the `source` column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### **image-predictions.tsv**\n",
    "1. Check the prediction that returs to **True dog**. The order of check is p1 -> p2 -> p3\n",
    "2. If all the three predition returns **False dog**, remove them directly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### **tweet_json.txt**\n",
    "Nothing to do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### **Merge three datasets**\n",
    "Using the inner merge and the tweet_id id.\n",
    "\n",
    "dataset shape ***before***:\n",
    "- twitter-archive-enhanced.csv = (2356, 17)\n",
    "- image-predictions.tsv        = (2075, 12)\n",
    "- tweet_json.txt               = (2331, 3)\n",
    "\n",
    "***After***\n",
    "- twitter_archive_master.csv   = (1658, 18)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
